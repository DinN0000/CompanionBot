/**
 * ë¡œì»¬ ì„ë² ë”© ìƒì„± ëª¨ë“ˆ
 * @xenova/transformersë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
 */

import { pipeline, type FeatureExtractionPipeline } from "@xenova/transformers";

// ì‹±ê¸€í†¤ íŒŒì´í”„ë¼ì¸
let embeddingPipeline: FeatureExtractionPipeline | null = null;

// ëª¨ë¸ ë¡œë”© ì¤‘ì¸ì§€ ì¶”ì 
let isLoading = false;
let loadingPromise: Promise<FeatureExtractionPipeline> | null = null;

// ============== ì¿¼ë¦¬ ì„ë² ë”© LRU ìºì‹œ ==============
// ê°™ì€ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë°˜ë³µë  ë•Œ ì„ë² ë”© ì¬ê³„ì‚° ë°©ì§€
const QUERY_CACHE_MAX_SIZE = 100;
const queryEmbeddingCache = new Map<string, { embedding: number[]; lastUsed: number }>();

/**
 * LRU ë°©ì‹ìœ¼ë¡œ ìºì‹œ ì •ë¦¬
 */
function pruneQueryCache(): void {
  if (queryEmbeddingCache.size <= QUERY_CACHE_MAX_SIZE) return;
  
  // lastUsed ê¸°ì¤€ ì •ë ¬í•˜ì—¬ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ
  const entries = [...queryEmbeddingCache.entries()];
  entries.sort((a, b) => a[1].lastUsed - b[1].lastUsed);
  
  const toRemove = entries.slice(0, entries.length - QUERY_CACHE_MAX_SIZE);
  for (const [key] of toRemove) {
    queryEmbeddingCache.delete(key);
  }
}

/**
 * ì„ë² ë”© íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
 * ì‘ê³  ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© (384 ì°¨ì›)
 */
async function getEmbeddingPipeline(): Promise<FeatureExtractionPipeline> {
  if (embeddingPipeline) {
    return embeddingPipeline;
  }

  // ì´ë¯¸ ë¡œë”© ì¤‘ì´ë©´ ê¸°ë‹¤ë¦¼
  if (isLoading && loadingPromise) {
    return loadingPromise;
  }

  isLoading = true;
  console.log("[Embedding] Loading model...");
  const startTime = Date.now();
  
  loadingPromise = pipeline(
    "feature-extraction",
    "Xenova/all-MiniLM-L6-v2" // 384ì°¨ì›, ë¹ ë¥´ê³  ê°€ë²¼ì›€
  );

  try {
    embeddingPipeline = await loadingPromise;
    console.log(`[Embedding] Model loaded in ${Date.now() - startTime}ms`);
    return embeddingPipeline;
  } finally {
    isLoading = false;
  }
}

/**
 * ğŸš€ ì‚¬ì „ ë¡œë”©: ë´‡ ì‹œì‘ ì‹œ í˜¸ì¶œí•˜ì—¬ ì²« ìš”ì²­ ì§€ì—° ë°©ì§€
 */
export async function preloadEmbeddingModel(): Promise<void> {
  try {
    await getEmbeddingPipeline();
  } catch (error) {
    console.warn("[Embedding] Preload failed:", error);
  }
}

/**
 * í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
 * LRU ìºì‹œë¡œ ë°˜ë³µ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ.
 * @param text ë³€í™˜í•  í…ìŠ¤íŠ¸
 * @param useCache ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ true, ì²­í¬ ì„ë² ë”© ì‹œ false ê¶Œì¥)
 * @returns 384ì°¨ì› ì„ë² ë”© ë²¡í„°
 */
export async function embed(text: string | null | undefined, useCache = true): Promise<number[]> {
  // null/undefined ì²˜ë¦¬
  if (text == null) {
    return new Array(384).fill(0);
  }

  // í…ìŠ¤íŠ¸ ì •ê·œí™”
  const cleanText = text.trim().slice(0, 512); // ìµœëŒ€ 512ì
  if (!cleanText) {
    return new Array(384).fill(0);
  }

  // ìºì‹œ í™•ì¸
  if (useCache) {
    const cached = queryEmbeddingCache.get(cleanText);
    if (cached) {
      cached.lastUsed = Date.now();
      return cached.embedding;
    }
  }

  const pipe = await getEmbeddingPipeline();
  const result = await pipe(cleanText, {
    pooling: "mean",
    normalize: true,
  });

  // Tensorë¥¼ ë°°ì—´ë¡œ ë³€í™˜
  const embedding = Array.from(result.data as Float32Array);

  // ìºì‹œ ì €ì¥
  if (useCache) {
    queryEmbeddingCache.set(cleanText, { embedding, lastUsed: Date.now() });
    pruneQueryCache();
  }

  return embedding;
}

/**
 * ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”©í•©ë‹ˆë‹¤.
 * ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ (ëª¨ë¸ ë‚´ë¶€ì—ì„œ ìˆœì°¨ ì²˜ë¦¬ë˜ë”ë¼ë„ Promise ì˜¤ë²„í—¤ë“œ ê°ì†Œ)
 * ì²­í¬ìš©ì´ë¯€ë¡œ ì¿¼ë¦¬ ìºì‹œ ì‚¬ìš© ì•ˆ í•¨ (vectorStoreì˜ ì˜ì† ìºì‹œ ì‚¬ìš©).
 * @param texts ë³€í™˜í•  í…ìŠ¤íŠ¸ ë°°ì—´
 * @returns ì„ë² ë”© ë²¡í„° ë°°ì—´
 */
export async function embedBatch(texts: (string | null | undefined)[]): Promise<number[][]> {
  // null/undefined ë°°ì—´ ì²˜ë¦¬
  if (!texts || texts.length === 0) return [];
  if (texts.length === 1) return [await embed(texts[0], false)];
  
  // ë™ì‹œì„± ì œí•œ (ë©”ëª¨ë¦¬ ë³´í˜¸)
  const CONCURRENCY = 5;
  const results: number[][] = new Array(texts.length);
  
  for (let i = 0; i < texts.length; i += CONCURRENCY) {
    const batch = texts.slice(i, i + CONCURRENCY);
    // ì²­í¬ ì„ë² ë”©ì€ ìºì‹œ ì‚¬ìš© ì•ˆ í•¨ (useCache=false)
    const batchResults = await Promise.all(batch.map(text => embed(text, false)));
    for (let j = 0; j < batchResults.length; j++) {
      results[i + j] = batchResults[j];
    }
  }
  
  return results;
}

/**
 * ì¿¼ë¦¬ ì„ë² ë”© ìºì‹œ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
 */
export function getQueryCacheStats(): { size: number; maxSize: number } {
  return { size: queryEmbeddingCache.size, maxSize: QUERY_CACHE_MAX_SIZE };
}

/**
 * ì¿¼ë¦¬ ì„ë² ë”© ìºì‹œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
 */
export function clearQueryCache(): void {
  queryEmbeddingCache.clear();
}

/**
 * ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
 * 
 * ìµœì í™”: embed()ì—ì„œ normalize: trueë¡œ ì •ê·œí™”ëœ ë²¡í„°ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ,
 * ì •ê·œí™”ëœ ë²¡í„°ì˜ ê²½ìš° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = ë‚´ì  (normì´ 1ì´ë¯€ë¡œ)
 * normalized íŒŒë¼ë¯¸í„°ê°€ trueë©´ ë‚´ì ë§Œ ê³„ì‚°í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ.
 */
export function cosineSimilarity(a: number[] | null | undefined, b: number[] | null | undefined, normalized = true): number {
  // null/undefined ë˜ëŠ” ë¹ˆ ë°°ì—´ ì²˜ë¦¬
  if (!a || !b || a.length === 0 || b.length === 0) return 0;
  if (a.length !== b.length) return 0;
  
  let dotProduct = 0;
  
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
  }
  
  // ì •ê·œí™”ëœ ë²¡í„°ë©´ ë‚´ì  = ì½”ì‚¬ì¸ ìœ ì‚¬ë„
  if (normalized) {
    return dotProduct;
  }
  
  // ì •ê·œí™”ë˜ì§€ ì•Šì€ ë²¡í„°ë©´ norm ê³„ì‚° í•„ìš”
  let normA = 0;
  let normB = 0;
  
  for (let i = 0; i < a.length; i++) {
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }
  
  const denominator = Math.sqrt(normA) * Math.sqrt(normB);
  if (denominator === 0) return 0;
  
  return dotProduct / denominator;
}
